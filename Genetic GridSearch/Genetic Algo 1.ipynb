{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Optional, Callable, Tuple\n",
    "from numpy import random\n",
    "import itertools\n",
    "import math\n",
    "import statistics\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse_score\n",
    "from sklearn.metrics import mean_absolute_error as mae_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape_score\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn_genetic.space import Categorical, Integer, Continuous\n",
    "\n",
    "import optuna\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from space import Space\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> Genetic algo with Adaptive Mutation</font>\n",
    "\n",
    "\n",
    "Fitness based adaptive Mutation<br>\n",
    "https://neptune.ai/blog/adaptive-mutation-in-genetic-algorithm-with-python-examples<br>\n",
    "https://www.atlantis-press.com/article/7393.pdf\n",
    "\n",
    "Rank based adaptive mutation <br>\n",
    "https://arxiv.org/pdf/2104.08842\n",
    "\n",
    "A good crossover operator for real encoding was proposed by K. Deb in 1995. Here is the paper: http://www.complex-systems.com/pdf/09-2-2.pdf\n",
    "\n",
    "Parameters \n",
    "1. Param Grid: Given\n",
    "2. Genome: One combination of Param Grid\n",
    "3. Population: All combinations of Param Grid considered\n",
    "\n",
    "Functions\n",
    "1. Genetic Representation of Genome, Population (solutions)\n",
    "2. Generating new solutions\n",
    "3. Fitness Value functions: MSE, MAE, etc\n",
    "4. Elitism/Selection Function: Choose which Genome to undergo CrossOver, can use python's choice function, weight = Fitness Value\n",
    "5. Cross over Function\n",
    "6. Mutation Algo: Usually mutation rate is set to 1/L, where L is the length of the bitstring.\n",
    "7. Evolution Algo\n",
    "\n",
    "Classes\n",
    "1. Genome\n",
    "2. Population\n",
    "3. GenomSearch\n",
    "    - GenomSearchCV\n",
    "\n",
    "\n",
    "Limitations\n",
    "1. Must be a range\n",
    "2. cannot pipeline\n",
    "\n",
    "Future:\n",
    "1. Allow for more flexible formatting of param_grid\n",
    "2. Take care of edge cases\n",
    "3. Convert to binary (maybe faster?)\n",
    "4. In population.mutation() -> Maybe can update f_max and f_avg as we are mutating, else can try parallel processing\n",
    "\n",
    "Fitness Function:\n",
    "Fine-tune the fitness function to better represent the problem's objectives and constraints. A well-designed fitness function guides the algorithm toward the desired solutions.\n",
    "\n",
    "Constraint Handling:\n",
    "Implement techniques for handling constraints effectively. Penalization or repair methods can ensure that generated solutions comply with the problem constraints.\n",
    "\n",
    "Diversity Preservation:\n",
    "Encourage diversity within the population to prevent premature convergence to local optima. Diversity-preserving techniques, such as crowding or fitness sharing, can help in maintaining a diverse set of solutions.\n",
    "\n",
    "Hybrid Approaches:\n",
    "Consider combining the genetic algorithm with other optimization techniques, such as local search or simulated annealing, to explore the search space more effectively.\n",
    "\n",
    "Parameter Tuning:\n",
    "Perform parameter tuning using techniques like grid search or genetic algorithms themselves to optimize the genetic algorithm's parameters for your specific problem.\n",
    "\n",
    "Parallelization:\n",
    "If your problem domain allows it, consider parallelizing the genetic algorithm to run multiple populations concurrently. This can significantly speed up the search process.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInput example:\\n\\nparam_grid = {\\'tol\\': Continuous(1e-2, 1e10, distribution=\\'log-uniform\\'),\\n              \\'alpha\\': Continuous(1e-5, 2e-5),\\n              \\'activation\\': Categorical([\\'logistic\\', \\'tanh\\']),\\n              \\'batch_size\\': Integer(300, 350)\\n             }\\n\\navailable dtypes:\\ncategory, int, float\\n\\npopulation = [Genome1, Genome2, Genome3, ...]\\n\\n\\nneed to make one for pipelining so like \"PCA__n componenes\"\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Input example:\n",
    "\n",
    "param_grid = {'tol': Continuous(1e-2, 1e10, distribution='log-uniform'),\n",
    "              'alpha': Continuous(1e-5, 2e-5),\n",
    "              'activation': Categorical(['logistic', 'tanh']),\n",
    "              'batch_size': Integer(300, 350)\n",
    "             }\n",
    "\n",
    "available dtypes:\n",
    "category, int, float\n",
    "\n",
    "population = [Genome1, Genome2, Genome3, ...]\n",
    "\n",
    "\n",
    "need to make one for pipelining so like \"PCA__n componenes\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config\n",
    "import os\n",
    "\n",
    "log_file_dir = \"log/\"\n",
    "log_file_name = \"log_1\"\n",
    "log_file = log_file_dir + log_file_name + \".txt\"\n",
    "\n",
    "if not os.path.exists(log_file_dir):\n",
    "    os.makedirs(log_file_dir)\n",
    "    print(\"log directory successfully created\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "class Genome():\n",
    "    def __init__(self, hyperparameters, **params):\n",
    "\n",
    "        self.initialise_shared_var(**params)\n",
    "\n",
    "        self.params = hyperparameters\n",
    "        self.fitness = self.calc_fitness(self.params)\n",
    "\n",
    "    @classmethod\n",
    "    def initialise_shared_var(cls, **params):\n",
    "        if not hasattr(cls, 'X_train'):\n",
    "            cls.X_train = params['X_train']\n",
    "        if not hasattr(cls, 'y_train'):\n",
    "            cls.y_train = params['y_train']\n",
    "        if not hasattr(cls, 'estimator'):\n",
    "            cls.estimator = params['estimator']\n",
    "        if not hasattr(cls, 'metric'):\n",
    "            cls.metric = params['metric']\n",
    "        if not hasattr(cls, 'cv'):\n",
    "            cls.cv = params['cv']\n",
    "        if not hasattr(cls, 'cv_shuffle'):\n",
    "            cls.cv_shuffle = params['cv_shuffle']\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def params(self):\n",
    "        return self._params\n",
    "\n",
    "    @params.setter\n",
    "    def params(self, new_params):\n",
    "        self.fitness = self.calc_fitness(new_params)\n",
    "        self._params = new_params\n",
    "\n",
    "\n",
    "    ## Comparing operators\n",
    "    def __lt__(self, other):\n",
    "        # Define custom behavior for \"<\"\n",
    "        return self.fitness < other.fitness\n",
    "\n",
    "    def __le__(self, other):\n",
    "        # Define custom behavior for \"<=\"\n",
    "        return self.fitness <= other.fitness\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        # Define custom behavior for \">=\"\n",
    "        return self.fitness >= other.fitness\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        # Define custom behavior for \"==\"\n",
    "        return self.fitness == other.fitness\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        # Define custom behavior for \"!=\"\n",
    "        return self.fitness != other.fitness\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.params.keys())\n",
    "    \n",
    "    def __repr__(self):\n",
    "        string = f'(Genome = Params : {self.params}, Fitness : {self.fitness})'\n",
    "        return string\n",
    "    \n",
    "    def extract(self, start, stop = None, step = 1):\n",
    "        \"\"\"\n",
    "        Just for ease of slicing\n",
    "        \n",
    "        Parameters\n",
    "        -----------------\n",
    "        key: Can be slice object\n",
    "        \"\"\"\n",
    "        if not stop: ## If stop == None, means only want extract one\n",
    "            return dict([list(self.params.items())[start]])\n",
    "            \n",
    "        elif stop > start and stop <= len(self):\n",
    "            target = dict([list(self.params.items())[i] for i in range(start, stop, step)])\n",
    "            return target\n",
    "        else:\n",
    "            raise IndexError(f\"Index out of range.\")\n",
    "\n",
    "    \n",
    "    def calc_fitness(self, params):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        -------------------\n",
    "        Takes in 1 genome/set of params\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        cv_shuffle = self.cv if self.cv_shuffle else 1\n",
    "\n",
    "        kf = RepeatedKFold(n_splits = self.cv, n_repeats = cv_shuffle, random_state = 2)\n",
    "\n",
    "        for train, test in kf.split(self.X_train):\n",
    "            X_train, X_test, y_train, y_test = self.X_train.iloc[train], self.X_train.iloc[test], self.y_train.iloc[train], self.y_train.iloc[test]\n",
    "\n",
    "            model = clone(self.estimator)\n",
    "            model.set_params(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            result = evaluate(y_test, y_pred, self.metric)\n",
    "            model = None\n",
    "            results += [result]\n",
    "\n",
    "        return statistics.mean(results)\n",
    "\n",
    "    \n",
    "    def mutate(self, param_grid, rate, verbose = False):\n",
    "        \"\"\"\"\n",
    "        Mutate one gene\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "        choices: Param_grid for choosing\n",
    "        rate: Mutation rate/ Probability of one parameter undergoing mutation\n",
    "\n",
    "        Returns\n",
    "        -------------------\n",
    "        Returns new gene\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(f'original: {self}')\n",
    "\n",
    "        length = len(self)\n",
    "        choices = list(range(0, length))\n",
    "        params = self.params.copy()\n",
    "        keys = list(params.keys())\n",
    "\n",
    "        for i in choices:\n",
    "            prob = random.random()\n",
    "            if prob < rate:   ## If 0 < prob and prob < rate, means falls under the possibility of mutating\n",
    "                key = keys[i]\n",
    "                target_val = params[key]\n",
    "                items = param_grid[key]\n",
    "                new_target_val = target_val\n",
    "\n",
    "                if isinstance(items, Categorical):\n",
    "                    if len(items) == 1:\n",
    "                        continue\n",
    "                else:\n",
    "                    while new_target_val == target_val:     ## Iterate until not the same \n",
    "                        new_target_val = items.sample()     ## Ok but i'm not sure if i should do this because sklearn didnt and it\n",
    "                                                            ## kind of ruins the sampling from a distribution purose\n",
    "\n",
    "                params[key] = new_target_val\n",
    "                if verbose:\n",
    "                    print(f\"After mutation: '{key}': '{new_target_val}'\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f'No mutation.')\n",
    "                continue\n",
    "\n",
    "        new_gene = Genome(params)\n",
    "\n",
    "        return new_gene\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population():\n",
    "\n",
    "\n",
    "    def __init__(self, population = None, **params):\n",
    "\n",
    "        self.initialise_shared_var(**params)\n",
    "\n",
    "        if not population:  ## If no population\n",
    "            self._population = self.generate_pop()\n",
    "        else:\n",
    "            self._population = population\n",
    "\n",
    "    @classmethod\n",
    "    def initialise_shared_var(cls, **params):\n",
    "        \n",
    "        if not hasattr(cls, 'X_train'):\n",
    "            cls.X_train = params['X_train']\n",
    "        if not hasattr(cls, 'y_train'):\n",
    "            cls.y_train = params['y_train']\n",
    "        if not hasattr(cls, 'estimator'):\n",
    "            cls.estimator = params['estimator']\n",
    "        if not hasattr(cls, 'param_grid'):\n",
    "            cls.param_grid = params['param_grid']\n",
    "        if not hasattr(cls, 'pop_size'):\n",
    "            cls.pop_size = params['pop_size']\n",
    "        if not hasattr(cls, 'metric'):\n",
    "            cls.metric = params['metric']\n",
    "        if not hasattr(cls, 'cv'):\n",
    "            cls.cv = params['cv']\n",
    "        if not hasattr(cls, 'cv_shuffle'):\n",
    "            cls.cv_shuffle = params['cv_shuffle']\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def population(self):\n",
    "        return tim_sort(self._population)\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def get_fit(self):\n",
    "        \"\"\"\n",
    "        Helps to get list of fitness values\n",
    "        \"\"\"\n",
    "        fits = []\n",
    "        for i in self.population:\n",
    "            fits += [i.fitness]\n",
    "        return fits\n",
    "\n",
    "\n",
    "    @population.setter\n",
    "    def population(self, new_pop):\n",
    "        self._population = new_pop\n",
    "\n",
    "    ## Used this only for sorting so it's easier\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, int):\n",
    "            return self.population[key]\n",
    "        \n",
    "        elif isinstance(key, slice):\n",
    "            start, stop, step = key.indices(self.n)\n",
    "            target = [self.population[i] for i in range(start, stop, step)]\n",
    "            return target\n",
    "        else:\n",
    "            raise TypeError(f\"Invalid Argument type. Must be int or slice.\")\n",
    "        \n",
    "    def __repr__(self):\n",
    "        string = \"\"\n",
    "        for genome in self.population:\n",
    "            string += f'{genome}\\n'\n",
    "        return string\n",
    "        \n",
    "    def copy(self):\n",
    "        \"\"\"\n",
    "        Makes a copy of the current generation\n",
    "        \"\"\"\n",
    "        pop_copy = [genome for genome in self.population]\n",
    "        return Population(pop_copy)\n",
    "            \n",
    "    \n",
    "    def calc_avg_fit(self):\n",
    "        \"\"\"\n",
    "        For adaptive Mutation\n",
    "        \"\"\"\n",
    "        fits = self.get_fit\n",
    "        return statistics.mean(fits)\n",
    "\n",
    "\n",
    "    def generate_pop(self):\n",
    "        random.seed(3)\n",
    "        \"\"\"\n",
    "        To initialize population\n",
    "\n",
    "        Parameters\n",
    "        --------------\n",
    "        n: Number of Genomes\n",
    "\n",
    "        Returns\n",
    "        ---------------\n",
    "        None\n",
    "\n",
    "        \"\"\"\n",
    "        genome_attributes = {\n",
    "            'X_train': self.X_train,\n",
    "            'y_train': self.y_train,\n",
    "            'estimator': self.estimator,\n",
    "            'metric': self.metric,\n",
    "            'cv': self.cv,\n",
    "            'cv_shuffle': self.cv_shuffle\n",
    "        }\n",
    "        \n",
    "        pop = []\n",
    "        for i in range(self.pop_size):\n",
    "            params = {}\n",
    "            for key in self.param_grid.parameters:\n",
    "                params[key] = self.param_grid[key].sample()\n",
    "            new_genome = Genome(params, **genome_attributes)\n",
    "            pop += [new_genome]\n",
    "\n",
    "        return pop\n",
    "\n",
    "\n",
    "    def elitism(self, n):\n",
    "        \"\"\"\n",
    "        To choose which n Genomes to bring over to next gen\n",
    "\n",
    "        Parameters\n",
    "        ------------------\n",
    "        n: prop of Genomes, default 0.2 of population\n",
    "\n",
    "        Returns\n",
    "        -----------------\n",
    "        Top n Genomes\n",
    "        \"\"\"\n",
    "        if not 0 < n < 1:\n",
    "            raise ValueError(\"n must be between 0 and 1\")\n",
    "        n = round(n*self.pop_size)\n",
    "        top_n = self.population[0:n]\n",
    "\n",
    "        return top_n\n",
    "\n",
    "\n",
    "    def n_cross_over(self, genes, n, nco_rate = 0.5, verbose = False):\n",
    "        \"\"\"\n",
    "        To cross over 2 genomes\n",
    "        \n",
    "        Parameters\n",
    "        ------------------------\n",
    "        genes: (a,b) Cross over genomes in pop[a] and pop[b]\n",
    "        n: Number of points to cross over\n",
    "        verbose: Illustrate parents to genomes\n",
    "        nco_rate: Cross over rate/ Probability of genes undergoing crossover\n",
    "            -> If rate = 0: None of the genes can undergo mutation\n",
    "            -> If rate = 1: All of the genes can undergo mutation\n",
    "        \n",
    "        Returns\n",
    "        ----------------------\n",
    "        2 Genomes, Crossed over, not in place\n",
    "        \"\"\"\n",
    "        a,b = genes\n",
    "        a = int(a)\n",
    "        b = int(b)\n",
    "        gene1 = self.population[a]\n",
    "        gene2 = self.population[b]\n",
    "\n",
    "        len1 = len(gene1)\n",
    "        len2 = len(gene2)\n",
    "        if len1 != len2:\n",
    "            raise ValueError(\"Genomes must be of same length\")\n",
    "        \n",
    "        if len1 < 2:\n",
    "            raise Exception(\"Too short!\")\n",
    "        \n",
    "        if n >= len1 -1:\n",
    "            raise Exception(f\"Too much cross-over points. Maximum is {len1-1}.\")\n",
    "\n",
    "        prob = random.random()\n",
    "\n",
    "        if prob > nco_rate:  \n",
    "            if verbose:\n",
    "                print(\"p value = %.5f is more than %f. No cross over.\" %(prob, nco_rate))\n",
    "            return [gene1, gene2]\n",
    "\n",
    "        choices = list(range(1,len1))\n",
    "        idx = list(np.random.choice(choices, size = n, replace = False))\n",
    "        idxs = tim_sort(idx + [0, len1]) \n",
    "        sections = n+1\n",
    "        params3 = {}\n",
    "        params4 = {}\n",
    "\n",
    "        for i in range(sections):\n",
    "            ## Even\n",
    "            if i%2 == 0:\n",
    "                params33 = gene1.extract(idxs[i], idxs[i+1])\n",
    "                params44 = gene2.extract(idxs[i], idxs[i+1])\n",
    "                \n",
    "                    \n",
    "            ## Odd\n",
    "            else:\n",
    "                params33 = gene2.extract(idxs[i], idxs[i+1])\n",
    "                params44 = gene1.extract(idxs[i], idxs[i+1])\n",
    "            \n",
    "            params3 = merge_dicts(params3, params33)\n",
    "            params4 = merge_dicts(params4, params44)\n",
    "                \n",
    "        gene3 = Genome(params3)\n",
    "        gene4 = Genome(params4)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'------------Parent Genomes------------\\n{gene1}\\n{gene2}\\n')\n",
    "            print(f'After {n}-point(s) crossover at index(es) : {idx}\\n')\n",
    "            print(f'------------Children Genomes-------------\\n{gene3}\\n{gene4}\\n')\n",
    "            print('================================================')\n",
    "\n",
    "        return [gene3, gene4]\n",
    "\n",
    "\n",
    "    def selection(self, n, subset = None):\n",
    "        \"\"\"\"\n",
    "        Purpose:\n",
    "        Helps n_cross_over by choosing what 2 genomes to put in\n",
    "        \n",
    "        Input:\n",
    "        'n': Number of parent pairs\n",
    "        'subset': [low,high) Genes in population to select from eg. gene index 4:7 (exclusive)\n",
    "\n",
    "        Output:\n",
    "        List of tuples of indexes: [ (parent1,parent2) ,(parent3, parent4)]\n",
    "        \"\"\"\n",
    "        if not subset:\n",
    "            low, high = (0, self.pop_size)\n",
    "            size = self.pop_size\n",
    "        else:\n",
    "            low, high = subset\n",
    "            size = high -low \n",
    "\n",
    "        max = math.comb(size, 2)\n",
    "        if n > max:\n",
    "            raise ValueError(f'Too much combinations. Maximum is {max}')\n",
    "\n",
    "        pairs = []\n",
    "        choices = list(range(low, high))\n",
    "        fits = self.get_fit[low:high]\n",
    "        p = [i/sum(fits) for i in fits]\n",
    "\n",
    "        for i in range(n):\n",
    "            parent1, parent2 = random.choice(choices, p = p, size = 2, replace = False)\n",
    "            pairs += [(parent1, parent2)]\n",
    "        \n",
    "        return pairs\n",
    "    \n",
    "    def fitness_mutation_rate(self, k, f_max, f_avg, f):\n",
    "        \"\"\"\n",
    "        Purpose:\n",
    "        Fitness-based adaptive mutation\n",
    "\n",
    "        Input:\n",
    "        k: (k1,k2) Tuple of 2 for constant, k1,k2 in (0,1)\n",
    "        f_max: Maximum fitness of population\n",
    "        f_avg: Average fitness of population\n",
    "        f: Current fitness value of Genome\n",
    "        \n",
    "        Output:\n",
    "        rate -> int\n",
    "        \"\"\"\n",
    "        k1, k2 = k\n",
    "        # print(f'k: {k}, f_max; {f_max}, f_avg: {f_avg}, f: {f}')\n",
    "        \n",
    "        if f >= f_avg:      ## High quality solution\n",
    "            rate = k1*( (f_max - f)/(f_max-f_avg) )\n",
    "        else:               ## Low quality solution\n",
    "            rate = k2\n",
    "        return rate\n",
    "\n",
    "    def rank_mutation_rate(self, p_max, r, n):\n",
    "        \"\"\"\"\n",
    "        Purpose:\n",
    "        Rank-based adaptive mutation\n",
    "        \n",
    "        Input:\n",
    "        p_max: Maximum mutation probability\n",
    "        r: Rank of chromosome\n",
    "        n: population size\n",
    "\n",
    "        Output:\n",
    "        rate -> int\n",
    "        \"\"\"\n",
    "        p = p_max*( 1- (r-1)/(n-1))\n",
    "        return p\n",
    "\n",
    "    def mutation(self, type, params, verbose = False, inplace = True):\n",
    "        \"\"\"\n",
    "        Purpose:\n",
    "        Randomly select from population without replacement and mutate\n",
    "\n",
    "        Input:\n",
    "        type: 'fitneses', 'random', 'rank'\n",
    "            Default\n",
    "            - 'fitness' : k = (k1,k2) = (0.05,0.06)\n",
    "            - 'random': rate = 0.5\n",
    "            -'rank': p_max = 0.08\n",
    "        inplace: Mutate on spot\n",
    "\n",
    "        Output:\n",
    "        Population with mutated genes, inplace\n",
    "\n",
    "        Warning:\n",
    "        Self.population has to be SORTED\n",
    "        \"\"\"\n",
    "        f_max = max(self.get_fit)\n",
    "        f_avg = self.calc_avg_fit()\n",
    "        new_pop = []\n",
    "\n",
    "        subset = self.population\n",
    "        ## Iterate through all the genome\n",
    "        for index, gene in enumerate(subset):\n",
    "            if type == 'fitness':\n",
    "                k = params['k']\n",
    "                rate = self.fitness_mutation_rate(k, f_max, f_avg, f = gene.fitness)\n",
    "\n",
    "            elif type == 'rank':\n",
    "                r = index\n",
    "                n = self.pop_size\n",
    "                p_max = params['p_max']\n",
    "                rate = self.rank_mutation_rate(p_max, r, n)\n",
    "\n",
    "            elif type == 'random':\n",
    "                rate = params['rate']\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"No such mutation type.\")\n",
    "            \n",
    "            new_gene = gene.mutate(self.param_grid, rate)\n",
    "            new_pop += [new_gene]\n",
    "        \n",
    "        if inplace:\n",
    "            self.population = new_pop\n",
    "            new_pop = self\n",
    "        else:\n",
    "            new_pop = Population(new_pop)\n",
    "\n",
    "        return new_pop\n",
    "    \n",
    "    def best_solution(self):\n",
    "        return self.population[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomeGrid():\n",
    "    def __init__(\n",
    "            self, \n",
    "            X, \n",
    "            y, \n",
    "            est, \n",
    "            parameters_grid, \n",
    "            cv = 5, \n",
    "            cv_shuffle = False, \n",
    "            max_evol = 100, \n",
    "            pop_size = 10, \n",
    "            mutation_type = 'rank', \n",
    "            scoring = 'recall', \n",
    "            el_prop = 0.2, \n",
    "            nco_rate = 0.5, \n",
    "            **params):\n",
    "        \"\"\"\n",
    "        Parameters/Attributes\n",
    "        -------------------\n",
    "        est: Model\n",
    "        param_grid: Parameters\n",
    "        max_evol: Max evolution\n",
    "        pop_size: Population size\n",
    "        mutation_type: 'fitneses', 'random', 'rank'\n",
    "\n",
    "        optional:\n",
    "        cross_valid\n",
    "        scoring: Evaluation criteria\n",
    "        elitism: Prop of population for elitism, default = 0.2\n",
    "        cross_over_rate/nco_rate: Default = 0.5\n",
    "        type: 'fitness', 'random', 'rank'\n",
    "            Default\n",
    "            - 'fitness' : k = (k1,k2) = (0.05,0.06)\n",
    "            - 'random': rate = 0.5\n",
    "            -'rank': p_max = 0.08\n",
    "        \n",
    "        \"\"\"\n",
    "        # global metric, estimator, param_grid, cv\n",
    "        # metric = scoring\n",
    "        # estimator = est\n",
    "        # cv = cross_valid\n",
    "\n",
    "        self.estimator = est\n",
    "        self.param_grid = Space(parameters_grid)\n",
    "        self.max_evol = max_evol\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_type = mutation_type\n",
    "        self.metric = scoring\n",
    "        self.el_prop = el_prop\n",
    "        self.nco_rate = nco_rate\n",
    "        self.best_hyperparameters = None\n",
    "        self.cv = cv\n",
    "        self.cv_shuffle = cv_shuffle\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "        if mutation_type == 'fitness':\n",
    "            self.mutation_para = {'k': params.get('k', (0.05, 0.06))}\n",
    "        elif mutation_type == 'random':\n",
    "            self.mutation_para = {'rate': params.get('rate', 0.5)}\n",
    "        elif mutation_type == 'rank':\n",
    "            self.mutation_para = {'p_max': params.get('p_max', 0.08)}\n",
    "        else:\n",
    "            raise Exception('No such mutation type')\n",
    "\n",
    "    @property\n",
    "    def best_model(self):\n",
    "        best_est = joblib.load('best_estimator.pkl')\n",
    "        return best_est\n",
    "\n",
    "\n",
    "    @property\n",
    "    def history(self):\n",
    "        history_log = joblib.load('history.pkl')\n",
    "        return history_log\n",
    "\n",
    "    # def n_splits(self, cv, X_train):\n",
    "    #     rows = X_train.shape[0]\n",
    "    #     split_size = rows//cv\n",
    "    #     nums = list(range(cv))*split_size\n",
    "    #     remainder = rows % cv\n",
    "    #     if remainder:       ## Assign the remaining ones into the last group\n",
    "    #         nums += [cv-1]*remainder\n",
    "        \n",
    "    #     return nums\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, early_term = True, early_term_thresh = 0.01, log = True, refit = True, verbose = False):\n",
    "        \"\"\"\n",
    "        Main function to fit\n",
    "        \n",
    "        Parameters\n",
    "        ------------------------\n",
    "        early_term: terminatate algorithms early, when flag >= 10\n",
    "        early_term_threshold: Flag += 1\n",
    "        refit: Auto fit to best model\n",
    "        verbose: True will also activate log (Write history in the file)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        ## For early term: flag += 1 when change <= thresh\n",
    "        if early_term:\n",
    "            flag = 0\n",
    "        \n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        population_attributes = {\n",
    "            \"X_train\": self.X_train,\n",
    "            \"y_train\": self.y_train,\n",
    "            \"X_test\": self.X_test,\n",
    "            \"y_test\": self.y_test,\n",
    "            \"estimator\": self.estimator,\n",
    "            \"param_grid\": self.param_grid,\n",
    "            \"pop_size\": self.pop_size,\n",
    "            \"metric\": self.metric,\n",
    "            \"cv\": self.cv,\n",
    "            \"cv_shuffle\": self.cv_shuffle\n",
    "        }\n",
    "        \n",
    "        pop = Population(**population_attributes)\n",
    "\n",
    "        ## For history\n",
    "        gen = []\n",
    "        fitness = []\n",
    "        fitnessMin = []\n",
    "        fitnessMax = []\n",
    "\n",
    "        ## For logging\n",
    "        if verbose:\n",
    "            string = \"Gen\\t\\tFitness\\t\\tFitnessMin\\t\\tFitnessMax\\n\"\n",
    "            with open(log_file, 'w') as log:\n",
    "                log.write(string)\n",
    "            print(string)\n",
    "            \n",
    "\n",
    "        for i in range(self.max_evol):\n",
    "\n",
    "            ## Early termination\n",
    "            if early_term:\n",
    "                if flag >= 10:\n",
    "                    break\n",
    "\n",
    "            ## Elitism: Choose top t\n",
    "            top_t = pop.elitism(self.el_prop)\n",
    "            parent_pairs = self.pop_size - len(top_t)\n",
    "\n",
    "            ## Selection: Make a list of tuple pairs for crossover from subset\n",
    "            parent_pairs = pop.selection(parent_pairs)\n",
    "\n",
    "            ## Cross Over subset\n",
    "            children = []\n",
    "            for pair in parent_pairs:\n",
    "                child = pop.n_cross_over(pair, 1, self.nco_rate, verbose)\n",
    "                children += child\n",
    "            \n",
    "            pop = top_t + children\n",
    "            pop = Population(pop)\n",
    "            \n",
    "            ## Mutate everything, including those carried over by elitism\n",
    "            pop.mutation(self.mutation_type, self.mutation_para, verbose = verbose)\n",
    "\n",
    "            ## For log/History\n",
    "            mini = pop.get_fit[0]\n",
    "            maxi = pop.get_fit[-1]\n",
    "            avg = pop.calc_avg_fit()\n",
    "            \n",
    "            gen.append(i)\n",
    "            fitness.append(avg)\n",
    "            fitnessMin.append(mini)\n",
    "            fitnessMax.append(maxi)\n",
    "\n",
    "            if early_term:\n",
    "                if i >= 1:\n",
    "                    if abs( avg - fitness[-1] ) < early_term_thresh:\n",
    "                        flag += 1\n",
    "                    else:\n",
    "                        flag = 0\n",
    "\n",
    "        \n",
    "            if verbose:\n",
    "                string = f'{i}\\t{avg}\\t{mini}\\t{maxi}\\n'\n",
    "                with open(log_file, \"a\") as log:\n",
    "                    log.write(string)\n",
    "                print(string)\n",
    "\n",
    "\n",
    "\n",
    "        best = pop.best_solution()\n",
    "        self.best_hyperparameters = best.params\n",
    "        history = {'gen':gen, 'fitness':fitness, 'FitnessMin': fitnessMin, 'fitnessMax': fitnessMax}\n",
    "        joblib.dump(history, 'history.pkl')\n",
    "\n",
    "        if refit:\n",
    "            model = clone(self.estimator)\n",
    "            model.set_params(**best.params)\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            joblib.dump(model, 'best_estimator.pkl')\n",
    "\n",
    "        end = time.time()\n",
    "        self.time_taken = end-start\n",
    "        \n",
    "        return best\n",
    "\n",
    "\n",
    "\n",
    "    def compare(self, param_grid_search, param_grid_ga, plot = True):\n",
    "        if not self.time_taken:\n",
    "            raise Exception('Model not fitted yet!')\n",
    "        \n",
    "        pred = self.best_model.predict(self.X_test)\n",
    "        cur_result = round(evaluate(self.y_test, pred, self.metric),5)\n",
    "\n",
    "        ## sklearn's Genetic Algo\n",
    "        start = time.time()\n",
    "        model_ga = clone(self.estimator)\n",
    "        model_ga = GASearchCV(estimator = model_ga, param_grid = param_grid_ga, verbose = False, scoring = 'recell', population_size = self.pop_size, generations = self.max_evol-1)\n",
    "        model_ga.fit(self.X_train, self.y_train)\n",
    "        end= time.time()\n",
    "        time_ga = end - start\n",
    "\n",
    "        pred = model_ga.predict(self.X_test)\n",
    "        ga_result = round(evaluate(self.y_test, pred, self.metric),5)\n",
    "\n",
    "        ## sklearn's GridSearch\n",
    "        start = time.time()\n",
    "        model_gs = clone(self.estimator)\n",
    "        model_gs = GridSearchCV(estimator = model_gs, param_grid = param_grid_search, scoring = 'recall', return_train_score = True)\n",
    "        model_gs.fit(self.X_train, self.y_train)\n",
    "        end = time.time()\n",
    "        time_gs = end - start\n",
    "        \n",
    "\n",
    "        pred = model_gs.predict(self.X_test)\n",
    "        gs_result = evaluate(self.y_test, pred, self.metric)\n",
    "\n",
    "        ## optuna\n",
    "        def op(trial):\n",
    "            params = {\n",
    "                'kernel': trial.suggest_categorical('kernel', ['linear','poly']),\n",
    "                'C': trial.suggest_float('C', 0, 1),\n",
    "                'gamma': trial.suggest_float('gamma', 0, 1)\n",
    "            }\n",
    "\n",
    "            model = svm.SVR(**params)\n",
    "            model.fit(self.X_train,self.y_train)\n",
    "            pred = model.predict(self.X_test)\n",
    "            result = round(evaluate(self.y_test, pred, self.metric),5)\n",
    "\n",
    "            return result\n",
    "\n",
    "        start = time.time()\n",
    "        optuna.logging.disable_default_handler()\n",
    "        model_op = optuna.create_study(direction = \"minimize\")\n",
    "        model_op.optimize(op, n_trials = self.max_evol)\n",
    "        end = time.time()\n",
    "        time_op = end - start\n",
    "\n",
    "        model_optuna = model_op.best_trial\n",
    "        model_optuna = svm.SVC(**model_op.best_params)\n",
    "        model_optuna.fit(self.X_train, self.y_train)\n",
    "        pred = model_optuna.predict(self.X_test)\n",
    "        op_result = round(evaluate(self.y_test, pred, self.metric),5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        table = [[\"         \", \"My GASearch\", \"sklearn GASearch\", \"sklearn GridSearchCV\", \"Optuna\"],\n",
    "                 [\"Test \" + self.metric, cur_result, ga_result, gs_result, op_result],\n",
    "                 [\"Time Taken\", self.time_taken, time_ga, time_gs, time_op]]\n",
    "\n",
    "        print(tabulate(table, headers = \"firstrow\", tablefmt=\"github\"))\n",
    "\n",
    "        print(f'My GASearch: {self.best_hyperparameters}\\nSklearn GASearchCV: {model_ga.best_params_}\\nSklearn GridSearchCV: {model_gs.best_params_}\\nOptuna: {model_op.best_params}\\n')\n",
    "\n",
    "        if plot:\n",
    "            y1 = self.history['fitness']\n",
    "            y2 = [ abs(i) for i in model_ga.history['fitness'] ]\n",
    "            y3 = [abs(i) for i in list(model_gs.cv_results_['mean_train_score'])]\n",
    "            trials = model_op.get_trials()\n",
    "            y4 = [trial.value for trial in trials if trial.state == optuna.trial.TrialState.COMPLETE and trial.value is not None]\n",
    "\n",
    "\n",
    "            x = list(range(self.max_evol))\n",
    "            n = max(len(y2), len(y3))\n",
    "\n",
    "            fig = go.Figure()\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = x[:len(y1)], y = y1, name = \"My GASearch\", mode = 'lines'))\n",
    "            fig.add_trace(go.Scatter(x = x, y = y2, name = \"Sklearn GASearchCV\", mode = 'lines'))\n",
    "            fig.add_trace(go.Scatter(x = x[:n], y = y3[:n], name = \"Sklearn GridSearchCV\", mode = 'lines'))\n",
    "            fig.add_trace(go.Scatter(x = x[:n], y = y4, name = \"Optuna\", mode = 'lines'))\n",
    "\n",
    "            fig.show()\n",
    "            \n",
    "            # plt.plot(x[:n],  y3[:n], label = \"Sklearn GridSearchCV\")\n",
    "            # plt.plot(x, y2, label = \"Sklearn GASearchCV\" )\n",
    "            # plt.plot(x[:len(y1)], y1, label = \"My GASearch\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            # plt.xlabel('Generations')\n",
    "            # plt.ylabel('Fitness')\n",
    "            # plt.title('Rate of convergence to optimal with Train data')\n",
    "\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> Parameter Grid </font><br>\n",
    "Remember to change model for optuna because idk how to out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from space import Categorical, Integer, Continuous\n",
    "from sklearn_genetic import space\n",
    "\n",
    "param_grid = {'kernel': Categorical(['linear','poly']),\n",
    "                        'C': Continuous(0,1),\n",
    "                        'gamma': Continuous(0,1)}\n",
    "\n",
    "param_grid_ga = {'kernel': space.Categorical(['linear','poly']),\n",
    "                        'C': space.Continuous(0,1),\n",
    "                        'gamma': space.Continuous(0,1)}\n",
    "\n",
    "param_grid_search = {'kernel': ['linear','poly'],\n",
    "                     'C': [random.uniform(0,1) for i in range(10)],\n",
    "                     'gamma': [random.uniform(0,1) for i in range(10)]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> Iris Dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m model \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC()\n\u001b[0;32m     14\u001b[0m pop \u001b[39m=\u001b[39m GenomeGrid(X,y,model, param_grid)\n\u001b[1;32m---> 15\u001b[0m pop\u001b[39m.\u001b[39;49mfit(log \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, verbose \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[6], line 126\u001b[0m, in \u001b[0;36mGenomeGrid.fit\u001b[1;34m(self, early_term, early_term_thresh, log, refit, verbose)\u001b[0m\n\u001b[0;32m    111\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    113\u001b[0m population_attributes \u001b[39m=\u001b[39m {\n\u001b[0;32m    114\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mX_train\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train,\n\u001b[0;32m    115\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcv_shuffle\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_shuffle\n\u001b[0;32m    124\u001b[0m }\n\u001b[1;32m--> 126\u001b[0m pop \u001b[39m=\u001b[39m Population(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpopulation_attributes)\n\u001b[0;32m    128\u001b[0m \u001b[39m## For history\u001b[39;00m\n\u001b[0;32m    129\u001b[0m gen \u001b[39m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m, in \u001b[0;36mPopulation.__init__\u001b[1;34m(self, population, **params)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialise_shared_var(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m      8\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m population:  \u001b[39m## If no population\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_population \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_pop()\n\u001b[0;32m     10\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_population \u001b[39m=\u001b[39m population\n",
      "Cell \u001b[1;32mIn[5], line 116\u001b[0m, in \u001b[0;36mPopulation.generate_pop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid\u001b[39m.\u001b[39mparameters:\n\u001b[0;32m    115\u001b[0m         params[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid[key]\u001b[39m.\u001b[39msample()\n\u001b[1;32m--> 116\u001b[0m     new_genome \u001b[39m=\u001b[39m Genome(params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenome_attributes)\n\u001b[0;32m    117\u001b[0m     pop \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [new_genome]\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m pop\n",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m, in \u001b[0;36mGenome.__init__\u001b[1;34m(self, hyperparameters, **params)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hyperparameters, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialise_shared_var(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams \u001b[39m=\u001b[39m hyperparameters\n\u001b[0;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalc_fitness(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n",
      "Cell \u001b[1;32mIn[4], line 31\u001b[0m, in \u001b[0;36mGenome.params\u001b[1;34m(self, new_params)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m@params\u001b[39m\u001b[39m.\u001b[39msetter\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparams\u001b[39m(\u001b[39mself\u001b[39m, new_params):\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc_fitness(new_params)\n\u001b[0;32m     32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_params \u001b[39m=\u001b[39m new_params\n",
      "Cell \u001b[1;32mIn[4], line 100\u001b[0m, in \u001b[0;36mGenome.calc_fitness\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     98\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     99\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m--> 100\u001b[0m result \u001b[39m=\u001b[39m evaluate(y_test, y_pred, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric)\n\u001b[0;32m    101\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    102\u001b[0m results \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [result]\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\Documents\\Genetic GridSearch\\helper.py:170\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(actual, predicted, metric)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Returns desired metrics'''\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m# try:    ## Classification Problem\u001b[39;00m\n\u001b[0;32m    168\u001b[0m metrics \u001b[39m=\u001b[39m {\n\u001b[0;32m    169\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m: accuracy_score(actual, predicted),\n\u001b[1;32m--> 170\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m\"\u001b[39m: f1_score(actual, predicted),\n\u001b[0;32m    171\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m\"\u001b[39m: recall_score(actual, predicted),\n\u001b[0;32m    172\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m\"\u001b[39m: precision_score(actual, predicted)\n\u001b[0;32m    173\u001b[0m             }\n\u001b[0;32m    174\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClassification Problem\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    175\u001b[0m \u001b[39m# except ValueError:  ## Regression Problem\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39m#     metrics = {\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[39m#                 \"r2\":r2_score(actual, predicted), \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39m#                 }\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[39m#     print(\"Regression Problem\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1238\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   1071\u001b[0m     {\n\u001b[0;32m   1072\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1096\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1097\u001b[0m ):\n\u001b[0;32m   1098\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \n\u001b[0;32m   1100\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[39m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1238\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[0;32m   1239\u001b[0m         y_true,\n\u001b[0;32m   1240\u001b[0m         y_pred,\n\u001b[0;32m   1241\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1242\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1243\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1244\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1245\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1246\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1247\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1411\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   1251\u001b[0m     {\n\u001b[0;32m   1252\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1279\u001b[0m ):\n\u001b[0;32m   1280\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1281\u001b[0m \n\u001b[0;32m   1282\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[39m    0.38...\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1411\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1412\u001b[0m         y_true,\n\u001b[0;32m   1413\u001b[0m         y_pred,\n\u001b[0;32m   1414\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[0;32m   1415\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1416\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1417\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1418\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1419\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1420\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1421\u001b[0m     )\n\u001b[0;32m   1422\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1563\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m \n\u001b[0;32m   1565\u001b[0m \u001b[39mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[39m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m zero_division_value \u001b[39m=\u001b[39m _check_zero_division(zero_division)\n\u001b[1;32m-> 1721\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1723\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1516\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1514\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1515\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1516\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1517\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1518\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1519\u001b[0m         )\n\u001b[0;32m   1520\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[0;32m   1521\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1522\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1523\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1526\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   1527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = load_iris(as_frame = True)\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "\n",
    "\n",
    "model = svm.SVC()\n",
    "\n",
    "pop = GenomeGrid(X,y,model, param_grid)\n",
    "pop.fit(log = False, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             |   My GASearch |   sklearn GASearch |   sklearn GridSearchCV |   Optuna |\n",
      "|-------------|---------------|--------------------|------------------------|----------|\n",
      "| Test mae    |       0.03333 |             0      |              0.0333333 |  0       |\n",
      "| Time Taken  |      12.4092  |            29.2629 |              4.50145   |  1.20667 |\n",
      "My GASearch: {'kernel': 'linear', 'C': 0.4546220755219468, 'gamma': 0.914313244392242}\n",
      "Sklearn GASearchCV: {'kernel': 'linear', 'C': 0.9490557490815773, 'gamma': 0.5299186822576124}\n",
      "Sklearn GridSearchCV: {'C': 0.4146852284662904, 'gamma': 0.3556187517565007, 'kernel': 'linear'}\n",
      "Optuna: {'kernel': 'linear', 'C': 0.9534813987180462, 'gamma': 0.19297209738084461}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "My GASearch",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          0.03888888888888889,
          0.03194444444444444,
          0.027777777777777776,
          0.02407407407407407,
          0.02361111111111111,
          0.023148148148148147,
          0.02222222222222222,
          0.02037037037037037,
          0.01712962962962963,
          0.016666666666666666,
          0.016666666666666666
         ]
        },
        {
         "mode": "lines",
         "name": "Sklearn GASearchCV",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.03916666666666667,
          0.02583333333333333,
          0.016666666666666666,
          0.01,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.011666666666666667,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.01,
          0.01,
          0.008333333333333333,
          0.01,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.009166666666666667,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.009166666666666667,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.009166666666666667,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.009166666666666667,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333,
          0.008333333333333333
         ]
        },
        {
         "mode": "lines",
         "name": "Sklearn GridSearchCV",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.01875,
          0.00625,
          0.01875,
          0.016666666666666666,
          0.01875,
          0.00625,
          0.01875,
          0.008333333333333333,
          0.01875,
          0.010416666666666666,
          0.01875,
          0.008333333333333333,
          0.01875,
          0.00625,
          0.01875,
          0.0125,
          0.01875,
          0.016666666666666666,
          0.01875,
          0,
          0.01666666666666667,
          0.00625,
          0.01666666666666667,
          0.0125,
          0.01666666666666667,
          0.00625,
          0.01666666666666667,
          0.008333333333333333,
          0.01666666666666667,
          0.008333333333333333,
          0.01666666666666667,
          0.008333333333333333,
          0.01666666666666667,
          0.00625,
          0.01666666666666667,
          0.012499999999999999,
          0.01666666666666667,
          0.014583333333333332,
          0.01666666666666667,
          0,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.014583333333333332,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.008333333333333333,
          0.020833333333333332,
          0.014583333333333332,
          0.020833333333333332,
          0.008333333333333333,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.016666666666666666,
          0.020833333333333332,
          0.016666666666666666,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.014583333333333332,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.008333333333333333,
          0.020833333333333332,
          0.014583333333333332,
          0.020833333333333332,
          0.008333333333333333,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.016666666666666666,
          0.020833333333333332,
          0.016666666666666666,
          0.020833333333333332,
          0.00625,
          0.014583333333333334,
          0.00625,
          0.014583333333333334,
          0.016666666666666666,
          0.014583333333333334,
          0.00625,
          0.014583333333333334,
          0.008333333333333333,
          0.014583333333333334,
          0.008333333333333333,
          0.014583333333333334,
          0.008333333333333333,
          0.014583333333333334,
          0,
          0.014583333333333334,
          0.014583333333333332,
          0.014583333333333334,
          0.008333333333333333,
          0.014583333333333334,
          0,
          0.012499999999999999,
          0.00625,
          0.012499999999999999,
          0.016666666666666666,
          0.012499999999999999,
          0.00625,
          0.012499999999999999,
          0.008333333333333333,
          0.012499999999999999,
          0.008333333333333333,
          0.012499999999999999,
          0.008333333333333333,
          0.012499999999999999,
          0,
          0.012499999999999999,
          0.014583333333333332,
          0.012499999999999999,
          0.008333333333333333,
          0.012499999999999999,
          0,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.016666666666666666,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.008333333333333333,
          0.020833333333333332,
          0.014583333333333332,
          0.020833333333333332,
          0.008333333333333333,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.016666666666666666,
          0.020833333333333332,
          0.016666666666666666,
          0.020833333333333332,
          0.00625,
          0.016666666666666666,
          0.00625,
          0.016666666666666666,
          0.016666666666666666,
          0.016666666666666666,
          0.00625,
          0.016666666666666666,
          0.008333333333333333,
          0.016666666666666666,
          0.008333333333333333,
          0.016666666666666666,
          0.008333333333333333,
          0.016666666666666666,
          0.00625,
          0.016666666666666666,
          0.016666666666666666,
          0.016666666666666666,
          0.008333333333333333,
          0.016666666666666666,
          0,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.014583333333333332,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.008333333333333333,
          0.020833333333333332,
          0.014583333333333332,
          0.020833333333333332,
          0.008333333333333333,
          0.020833333333333332,
          0.00625,
          0.020833333333333332,
          0.0125,
          0.020833333333333332,
          0.016666666666666666,
          0.020833333333333332,
          0,
          0.01875,
          0.00625,
          0.01875,
          0.014583333333333334,
          0.01875,
          0.00625,
          0.01875,
          0.008333333333333333,
          0.01875,
          0.008333333333333333,
          0.01875,
          0.008333333333333333,
          0.01875,
          0.00625,
          0.01875,
          0.016666666666666666,
          0.01875,
          0.008333333333333333,
          0.01875,
          0
         ]
        },
        {
         "mode": "lines",
         "name": "Optuna",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.03333,
          0.1,
          0.06667,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.06667,
          0.13333,
          0.03333,
          0.03333,
          0.03333,
          0.06667,
          0.06667,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.8,
          0.03333,
          0.03333,
          0.06667,
          0.03333,
          0.06667,
          0.03333,
          0.1,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.1,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0,
          0.06667,
          0.03333,
          0.03333,
          0.03333,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.03333,
          0.03333,
          0,
          0.03333,
          0,
          0.03333,
          0,
          0.03333,
          0,
          0.03333,
          0.03333,
          0,
          0.03333,
          0,
          0.03333,
          0.03333,
          0,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0.03333,
          0,
          0,
          0,
          0.03333,
          0.03333,
          0.03333,
          0,
          0.03333,
          0.03333,
          0.03333
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pop.compare(param_grid_search, param_grid_ga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> Diabetes dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVR()\n\u001b[0;32m     10\u001b[0m pop \u001b[39m=\u001b[39m GenomeGrid(model, param_grid)\n\u001b[1;32m---> 11\u001b[0m pop\u001b[39m.\u001b[39;49mfit(X,y,log \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, cv_shuffle \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, verbose \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[16], line 116\u001b[0m, in \u001b[0;36mGenomeGrid.fit\u001b[1;34m(self, X, y, early_term, early_term_thresh, log, refit, cv, cv_shuffle, verbose)\u001b[0m\n\u001b[0;32m    101\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    103\u001b[0m population_attributes \u001b[39m=\u001b[39m {\n\u001b[0;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mX_train\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train,\n\u001b[0;32m    105\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcv_shuffle\u001b[39m\u001b[39m\"\u001b[39m: cv_shuffle\n\u001b[0;32m    114\u001b[0m }\n\u001b[1;32m--> 116\u001b[0m pop \u001b[39m=\u001b[39m Population(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpopulation_attributes)\n\u001b[0;32m    118\u001b[0m \u001b[39m## For history\u001b[39;00m\n\u001b[0;32m    119\u001b[0m gen \u001b[39m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m, in \u001b[0;36mPopulation.__init__\u001b[1;34m(self, population, **params)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialise_shared_var(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m      8\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m population:  \u001b[39m## If no population\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_population \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_pop()\n\u001b[0;32m     10\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_population \u001b[39m=\u001b[39m population\n",
      "Cell \u001b[1;32mIn[15], line 116\u001b[0m, in \u001b[0;36mPopulation.generate_pop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid\u001b[39m.\u001b[39mparameters:\n\u001b[0;32m    115\u001b[0m         params[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid[key]\u001b[39m.\u001b[39msample()\n\u001b[1;32m--> 116\u001b[0m     new_genome \u001b[39m=\u001b[39m Genome(params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenome_attributes)\n\u001b[0;32m    117\u001b[0m     pop \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [new_genome]\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m pop\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mGenome.__init__\u001b[1;34m(self, hyperparameters, **params)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hyperparameters, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialise_shared_var(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams \u001b[39m=\u001b[39m hyperparameters\n\u001b[0;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalc_fitness(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n",
      "Cell \u001b[1;32mIn[14], line 31\u001b[0m, in \u001b[0;36mGenome.params\u001b[1;34m(self, new_params)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m@params\u001b[39m\u001b[39m.\u001b[39msetter\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparams\u001b[39m(\u001b[39mself\u001b[39m, new_params):\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc_fitness(new_params)\n\u001b[0;32m     32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_params \u001b[39m=\u001b[39m new_params\n",
      "Cell \u001b[1;32mIn[14], line 100\u001b[0m, in \u001b[0;36mGenome.calc_fitness\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     98\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     99\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m--> 100\u001b[0m result \u001b[39m=\u001b[39m evaluate(y_test, y_pred, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric)\n\u001b[0;32m    101\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    102\u001b[0m results \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [result]\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\Documents\\Genetic GridSearch\\helper.py:165\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(actual, predicted, metric)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(actual, predicted, metric):\n\u001b[0;32m    163\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Returns desired metrics'''\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     metrics \u001b[39m=\u001b[39m {\n\u001b[1;32m--> 165\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m: accuracy_score(actual, predicted),\n\u001b[0;32m    166\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m\"\u001b[39m:r2_score(actual, predicted), \n\u001b[0;32m    167\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m\"\u001b[39m:mse_score(actual, predicted)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[0;32m    168\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m:mse_score(actual, predicted), \n\u001b[0;32m    169\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m\"\u001b[39m:mae_score(actual, predicted),\n\u001b[0;32m    170\u001b[0m                 }\n\u001b[0;32m    172\u001b[0m     \u001b[39mreturn\u001b[39;00m metrics[metric]\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ZOEYIQINLUA\\.conda\\envs\\genEnv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "df = load_diabetes(as_frame = True)\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "model = svm.SVR()\n",
    "\n",
    "pop = GenomeGrid(model, param_grid)\n",
    "pop.fit(X,y,log = False, cv_shuffle = False, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pop\u001b[39m.\u001b[39mcompare(param_grid_search, param_grid_ga)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pop' is not defined"
     ]
    }
   ],
   "source": [
    "pop.compare(param_grid_search, param_grid_ga)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
